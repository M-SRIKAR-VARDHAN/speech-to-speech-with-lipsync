# speech-to-speech-with-lipsync

## ðŸ“‚ Repository Structure

```bash
ðŸ“‚ demo
â”œâ”€â”€ 1.py
â”œâ”€â”€ 1.txt
â”œâ”€â”€ 3.py
â”œâ”€â”€ Advanced-RVC-Inference
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ configs
â”‚   â”‚   â”œâ”€â”€ 32k.json
â”‚   â”‚   â”œâ”€â”€ 40k.json
â”‚   â”‚   â””â”€â”€ 48k.json
â”‚   â”œâ”€â”€ hubert_base.pt
â”‚   â”œâ”€â”€ lib
â”‚   â”‚   â”œâ”€â”€ audio.py
â”‚   â”‚   â”œâ”€â”€ commons.py
â”‚   â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ my_convert.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ vc_infer_pipeline.py
â”‚   â””â”€â”€ weights
â”‚       â”œâ”€â”€ modi.pth
â”‚       â”œâ”€â”€ model.index
â”‚       â””â”€â”€ ...
â”œâ”€â”€ dubbed_test.mp4
â”œâ”€â”€ lip.py
â”œâ”€â”€ main.py
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ translation
â”‚   â”‚   â””â”€â”€ nllb-en-te
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ model.safetensors
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ tts
â”‚   â”‚   â””â”€â”€ mms-tel
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ model.safetensors
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ whisper
â”‚       â””â”€â”€ base.en.pt
â”œâ”€â”€ output.mp4
â”œâ”€â”€ requirment.txt
â”œâ”€â”€ temp
â”‚   â””â”€â”€ result.avi
â”œâ”€â”€ test.mp4
â”œâ”€â”€ test_converted.wav
â”œâ”€â”€ test_translated.wav
â””â”€â”€ wav2Lip
    â”œâ”€â”€ checkpoints
    â”‚   â”œâ”€â”€ wav2lip.pth
    â”‚   â””â”€â”€ wav2lip_gan.pth
    â”œâ”€â”€ face_detection
    â”‚   â”œâ”€â”€ api.py
    â”‚   â”œâ”€â”€ core.py
    â”‚   â””â”€â”€ sfd
    â”‚       â”œâ”€â”€ net_s3fd.py
    â”‚       â””â”€â”€ s3fd.pth
    â”œâ”€â”€ inference.py
    â”œâ”€â”€ models
    â”‚   â”œâ”€â”€ conv.py
    â”‚   â”œâ”€â”€ syncnet.py
    â”‚   â””â”€â”€ wav2lip.py
    â”œâ”€â”€ preprocess.py
    â””â”€â”€ requirements.txt
